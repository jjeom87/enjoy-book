# 구글 엔지니어에게 듣는 네트워킹과 웹 성능 최적화 기법

## 1부 네트워킹 기초
### 1장 레이턴시와 대역폭 이해의 첫걸음
#### 속도는 하나의 특징이다
* 레이턴시 : 패킷을 전송하는 곳에서부터 전달받는 곳까지 이동하는 데 걸리는 시간
* 대역폭 : 논리적인 혹은 물리적인 통신 경로의 최대 처리량
#### 레이턴시의 구성요소
* 전파지연 (propagation delay) : 메시지가 송신측(Sender)에서 수신측(Receiver)으로 이동하는데 필요한 시간. 총 이동 거리 대비 신호가 이동하는 속도로 측정된다.
* 전송지연 (transmission delay) : 링크롤 패킷을 모든 비트를 내보내는 데 필요한 시간. 패킷의 길이 대비 링크의 데이터 전송 속도로 측정된다.
* 프로세싱 지연 (processing delay) : 패킷 해더를 처리하고 비트 수준의 에러를 체크하고 패킷의 목적지를 알아내는 데 필요한 시간.
* 큐잉 지연 (queuing delay) : 패킷이 처리될 때까지 큐(queue)에서 대기하는 시간
#### 빛의 속도와 전파 지연
* 광섬유의 보편적인 굴절률은 1.4 ~ 1.6
* 사용자들을 잘 붙잡아 두는 동시에 최고의 사용자 경험을 제공하기 위해서 애플리케이션은 수백 밀리초 이내에 응답할 수 있어야 함
#### 최종 마일 레이턴시
* 최종 마일 레이턴시는 인터넷 제공업체, 사용되는 기술, 네트워크의 토폴로지, 시간대에 따라 변경됨
#### 코어 네트워크의 대역폭
* 광섬유는 파장 분할 다중화를 통해 각 섬유마다 다른 파장의 빛을 이동시킬 수 있으므로 대역폭에 있어서는 확실한 이점을 가짐
* 광섬유 링크의 총 대역폭은 다중 송신되는 채널의 수에 채널별 데이터 전송률을 곱한 만큼의 값
#### 네트워크 가장자리에서의 대역폭
* 접속자 수가 많거나 하드웨어 오류 혹은 네트워크를 향한 디도스(DDOS) 공격 같은 여러가지 원인으로 인해 네트워크가 정체될 수 있음
#### 높은 대역폭과 낮은 레이턴시 제공
* 대역폭과 빛의 속도라는 한계점을 분명하게 인식하여 프로토콜과 네트워킹 코드를 설계하고 최적화해야만 애플리케이션 성능을 향상 시킬 수 있음
### 2장 TCP의 구성요소
* IP(Internet Protocol)는 호스트에서 호스트로의 라우팅과 주소할당 기능을 제공
* TCP(Transmission Control Protocol) 신뢰성을 보장해주는 네트워크 기능을 제공
* TCP는 신뢰할 수 없는 채널 위에 신뢰성을 구축한 추상 계층
* 네트워크 통신 구현에 필요한 유실 데이터 재전송, 전송 순서 확인, 혼잡 제어 및 회피 데이터 무결성 확인 같은 복잡한 기능을 투명하게 처리하여 애플리케이션 구현을 한결 쉽게 만듬
* TCP 스트림의 특징 중 하나가, 전송된 모든 바이트는 수신된 모든 바이트와 한 치의 오차 없이 동일
* 클라이언트에서 전송한 바이트 순서대로 도착
* TCP는 신속한 데이터 전송보다는 정확한 데이터의 전송에 더 특화
* HTTP 표준은 전송 프로토콜로서 오직 TCP만을 명시하고 있지 않음
#### 3-Way 핸드셰이크
* SYN : 클라이언트가 무작위로 시퀀스 번호 X를 고르고 SYN 패킷을 보낸다. 그 밖의 다른 TCP 플래그나 옵션 값들을 포함할 수 있다.
* SYN ACK : 서버가 시퀀스 번호 X를 1만큼 증가시키고, 무작위 시퀀스 번호 y를 고른다. 서버 또한 플래그와 옵션 값들을 추가한 후 응답을 보낸다.
* ACK : 클라이언트가 X와 Y를 모두 1만큼 증가시킨 후 마지막 ACK 패킷을 보냄으로써 핸드셰이크 과정을 종료한다.
* 3-Way 핸드셰이크가 끝나면 애플리케이션 데이터가 클라이언트와 서버 사이에 오고 갈 수 있음
* 3-Way 핸드셰이크로 인해 발생하는 지연이 크기 때문에, 새로운 TCP 커넥션을 맺는 것보다 기존에 연결되어 있는 TCP 커넥션을 재사용하는 것이 TCP에서 작동하는 애플리케이션을 최적화하는 데에 아주 중요한 역할을 함
#### 혼잡 제어 및 회피
##### 흐름제어
* 흐름 제어는 송신자가 수신자에게 처리하지 못할 만큼의 많은 데이터를 전송하는 것을 미리 방지하는 매커니즘
* 리시브 윈도를 통지하여 수신 데이터를 저장할 버퍼 공간의 크기를 서로에게 알려줌
* 일단 커넥션이 이루어지면 양쪽에서 자신들의 시스템 기본 설정값을 이용하여 rwnd 값을 초기화함
##### 느린 시작
* 혼잡 윈도 크기 : 클라이언트로부터 응답 확인 신호를 받기 전에 송신자 측에서 지정하는 최대 송신 데이터량
* 서버와 클라이언트는 어떻게 혼잡 윈도 크기의 최적값을 알아내는 것일까?
* 커넥션의 초반에는 천천히 시작해서 ACK 패킷을 받으면서 점점 윈도 사이즈를 늘려 나가는 것
* 느린 시작이 최대로 사용할 수 있는 대역폭에 제한을 둠으로써 용량이 작은 데이터를 전송하는 데에는 부작용으로 다가옴
##### 혼잡 회피
* 패킷 손실이 일어나지 않는 경우는 없고 그보다 패킷 손실이 언제 발생하는가를 파악하는 것이 더 중요
* 암묵적으로 판단하기에 패킷 손실이 일어났다는 것은 네트워크 혼잡이 일어났다는 신호
* 이동 경로의 어딘가에서 정체가 일어난 링크나 라우터가 패킷을 손실을 막기 위해 원도 사이즈를 조정
* 일단 혼잡 윈도가 리셋되면, 혼잡 회피는 더 이상의 손실을 최소화 하기 위해 얼마나 윈도 크기를 늘려야 할지를 지정
#### 대역폭 지연 곱
* 데이터 링크의 허용량과 종단 간 지연을 곱한 값, 결과값은 ACK를 받지 않고 이동할 수 있는 데이터의 최대 양
#### Head-of-Line 블로킹
* 수신자에게 이동 중인 패킷 하나가 소실되면 다른 모든 패킷들은 소실된 패킷이 재전송될 때까지 수신자 쪽 TCP 버퍼에서 대기
* TCP 계층 내에서 이루어지기 때문에 애플리케이션에서는 TCP의 데이터 재전송 여부나 큐에 들어있는 패킷 버퍼를 살펴볼 수가 없음
* 애플리케이션 입장에서는 그저 소켓에서 데이터를 읽으려 했을 때 전달 지연을 겪게 될 뿐
* HOL 블로킹의 
  * 장점
    * 애플리케이션이 패킷의 재배치나 재조합에 관여할 필요가 없기 때문에 애플리케이션의 코드 자체는 훨씬 간단해짐
  * 단점
    * 패킷이 도착하는 시간이 들쭉날쭉 (jitter) 해서 레이턴시를 예측하기 어렵다는 점
#### TCP의 최적화
##### 서버 설정 조정하기
* 사용하는 호스트를 최신 시스템 버전으로 업그레이드
* TCP의 초기 혼잡 원도 크기 증가
* 느린 시작 다시 시작하기
* 윈도 스케일링
* TCP Fast Open
##### 애플리케이션의 동작 튜닝하기
* 비트를 보내지 않는 것보다 빠른 방법은 없다. 즉, 더 적은 수의 비트를 전송
* 데이터를 빨리 이동하게 할 수는 없지만 이동 거리를 줄일 수는 있다.
* TCP 커넥션 재사용은 성능 향상에 매우 중요하다.
##### 성능 체크리스트
* 서버 커널을 최신버전으로 업그레이드하라.
* 혼잡 윈도 크기를 10으로 설정하라.
* 유휴 상태 후 느린 시작을 비활성화하라.
* 윈도 스케일링을 활성화하라.
* 전송 데이터를 압축하라.
* 서버를 사용자와 가까운 곳에 배치하여 왕복 시간을 줄여라.
* 기존 TCP 거넥션을 가능한 한 재사용하라.
### 3장 UDP의 구성요소
* 데이터그램 : 전송 네트워크 계층에서 보장하는 신뢰 기반의 데이터 교환에 의존하지 않고, 충분한 양의 정보를 발신지에서 목적지까지 스스로 운반할 수 있는 독립적인 데이터 개체.
#### Null 프로토콜 서비스
* 메시지를 무사히 운반할 수 있다는 보장 없음
* 메시지를 순서대로 운반할 수 없음
* 커넥션 상태 트래킹 없음
* 혼잡 제어 없음
#### UDP와 네트워크 주소 변환기
* IPv4 주소 부족 문제를 해결하기 위해 1994년 중반에 IP Network Address Translator (RFC 1631) 스펙이 처음으로 소개
* 네트워크 끝에 NAT 기기를 설치해서, 로컬 IP와 포트 번호를 한 개 이상의 고유 공용 IP와 포트 번호에 짝지어 관리
##### 연결 상태 타임아웃
* UDP에서 NAT 변환 작업을 할 때 가장 큰 문제는 데이터 운반을 위해 라우팅 레이블을 관리
* UDP는 커넥션 상태 정보가 없으므로 참조할 수 있는 것이 없음
##### NAT 통과
* NAT 안쪽에 위치한 내부 클라이언트가 자신의 공용 IP를 모름
* 공용 IP를 안다고 해서 무조건 UDP로 데이터를 전송할 수 있는 것은 아님
* NAT의 공용 IP에 도착하는 모든 패킷은 반드시 목적지 포트를 포함해야 하고, 그 값이 NAT 테이블 내에 있어야 하며, 이를 내부 수신 호스트 IP와 포트 튜플로 변환할 수 있어야 함
##### STUN, TURN 그리고 ICE
* STUN (Session Traversal Utilities for NAT) : 호스트 애플리케이션이 네트워크상의 NAT 기기를 발견하고 현재의 커넥션에 지정된 공용 IP와 포트 튜플을 알아낼 수 있게 하는 프로토콜
* TURN (Traversal Using Relays around NAT) : STUN 실패했을 때 UDP를 버리고 TCP로 전환하는 기능\
* ICE (Interactive Connectivity Establishment) : 네트워크 참여자 간에 가장 효율적인 터널을 찾을 수 있는 프로토콜
#### UDP 최적화
* 인터넷 경로 상황에 폭넑게 대응할 수 있어야 한다.
* 데이터 전송률을 조절할 수 있어야 한다.
* 모든 트래픽의 혼잡 제어를 수행할 수 있어야 한다.
* TCP와 비슷한 대역폭을 사용해야 한다.
* 패킷 손실이 있을 때에는 재전송 카운터를 중단해야 한다.
* Path MTU를 넘어서는 데이터그램을 전송해서는 안 된다.
* 데이터그램 손실, 중복, 재정렬을 처리할 수 있어야 한다.
* 최대 전송지연 2분까지 감당할 수 있도록 설계해야 한다.
* IPv4 UDP 체크섬과 IPv6 체크섬을 반드시 활성화해야 한다.
* 필요한 경우 최소 15초 간격으로 킵얼라이브를 사용할 수 있다.
### 4장 전송 계층 보안
* SSL 프로토콜은 넷스케이프에서 전자상거래 보안을 강화하기 위해 처음 개발됨
* 암호화, 인증처리, 데이터무결성 등 여러 보안 기제가 필요한데, SSL 프로토콜은 TCP의 바로 위애서 작동함 (세션계층 ,TLS)
* SSL의 명칭이 TLS(Transport Layer Security, 전송 계층 보안)로 변경 
#### 암호화, 인증 그리고 무결성
* 암호화 : 한 컴퓨터에서 다른 컴퓨터로 보내는 데이터를 타인이 알아볼 수 없도록 하는 매커니즘
* 인증 : 제공된 식별 정보의 진위 여부를 확인하는 메커니즘
* 무결성 : 메시지가 무단으로 변경되었거나 위조되었는지 확인하는 메커니즘
#### TLS 핸드셰이크
* 클라이언트와 서버가 TLS를 통해 애플리케이션 데이터를 주고받기 전에, 먼저 암호화된 터널을 형성해야 함
* 모든 TLS 커넥션이 TCP 핸드셰이크에 추가로 최대 두 번의 왕복 시간을 요구함
##### 애플리케이션 계층 프로토콜 협상(ALPN) ??
* TLS 핸드셰이크 과정에서 애플리케이션 프로토콜 협상할 수 있게 하는 TLS 확장
##### 서버 이름 표시 (Server Name Indication, SNI)
* 서버 이름 표시는 TLS 핸트셰이크가 시작될 때 클라이언트가 연결하려는 호스트 명을 지정 할 수 있다. 
따라서 웹 서버가 서버 이름 표시 호스트 명을 살펴보고 해당 인증서를 선택하여 핸트세이크를 진행 할 수 있음
#### TLS 세션 재개
* TSL는 여러 커넥션 사이에서 동일한 비밀키 데이터를 재개하거나 공유할 수 있음
##### 세션 식별자 (ID)
* 서버가 TLS 협상 도중에 "ServerHello" 메세지의 일부로 32바이트 세션 식별자를 생성하고 전송하도록 하는 장치
##### 세션 티켓
* 세션 티켓 교체 메커니즘을 사용하면 서버가 각 클라이언트마다 고유 세션 상태를 보유하지 않음
* 클라이언트가 서버에게 세션 티켓 지원 여부를 알려주면, TLS 핸드셰이크의 마지막 교환 단계에서 서버가 자신만의 비밀키로 모든 세션 데이터를 암호화하여 세션 티켓 레코드를 포함
* 세션 티켓은 클라이언트가 보관
#### 신뢰 사슬(Chain of Trust)과 인증기관
* 수동으로 지정된 인증서 : 모든 브라우저와 운영체제에는 사용자가 신뢰하는 인증서를 수동으로 불러올 수 있는 기능이 있다. 그 인증서를 어떤 경로로 얻어서 신뢰성을 확인할지는 모두 사용자에게 달려 있다.
* 인증기관 : 인증기관(CA)은 인증서의 사용자와 그 인증서를 의존하고 있는 단체 모두가 신뢰하고 있는 제3의 단체다.
* 브라우저와 운영체제 : 모든 운영체제와 브라우저는 잘 알려진 인증기관의 목록을 보유하고 있다. 따라서 해당 소프트웨어 판매업체가 관리하고 있는 신뢰할 만한 단체의 목록을 자동적으로 신뢰하게 된다.
#### 인증서 폐기
* 인증서의 개인키가 노출되거나, 인증기관 자체가 해킹 공격을 당하는 경우, 혹은 인증서를 교체해야 하거나 소속 기관이 바뀌는 경우처럼 사요한 이유로도 인증서를 폐기할 수 있음
##### 인증서 폐기 리스트 (Certificate Revocation List, CRL)
* 각 인증기관은 폐기된 인증서의 시리얼 넘버를 리스트로 만들어 주기적으로 발표
##### 온라인 인증 상태 프로토콜(OSCP)
* 폐기된 인증서의 시리얼 넘버를 모두 보유하고 있는 CRL과는 달리, OCSP에서는 클라이언트가 직접 인증서 데이터베이스에 쿼리를 날려 시리얼 넘버의 유효성을 실시간으로 체크
#### TLS 레코드 프로토콜
* 여러 종류의 메시지(핸드셰이크, 알림, 혹은 'Content Type' 필드를 통한 데이터)를 구분하고, 각 메시지의 무결성을 체크하고 보호하는 기능
* 애플리케이션에 맞는 레코드 사이즈를 선택하는 것이 최적화에 중요한 영향을 미칠 수 있음
#### TLS 최적화
##### 연산처리 비용
* 암호화된 채널을 구축하고 관리하려면 양쪽 피어에게 추가 연산처리 비용이 듬
##### 조기종료
* 조기 종료를 구현하는 가장 간단한 방법은 데이터와 서비스를 전 세계에 골고루 분포된 서버에 복제하거나 캐시에 저장
##### 세션 캐싱과 상태를 유지하지 않는 재개
* TLS 세션 캐싱에 중요한 역할을 하는 세션 식별자는 SSL 2.0에서 처음으로 소개되었으며 대부분의 클라이언트와 서버도 이를 지원하고 있음
##### TLS 레코드 사이즈
* 레코드 사이즈가 작으면 오버헤드가 늘어나고, 레코드 사이즈가 크면 레이턴시가 늘어남
* 적당한 레코드 사이즈를 단순히 수치로 정의하기 어려움
##### TLS 압축
* 레코드 프로토콜 내에서 전송되는 데이터를 무손실로 압축하는 방법
* 2012년에 발표된 '범죄' 공격이 TLS 압축을 조정하여 비밀 인증 쿠키를 노출시킴으로써 해커들이 세션 하이재킹을 시도할 수 있다고 한다.
* 전송 계층 TLS 압축은 전송할 콘텐츠를 알 수 없기 때문에 이미 압축된 파일 (이미지, 비디오 등)을 재 압축할 우려가 있다.
* 이중 압축은 서버와 클라이언트 양쪽의 CPU 시간을 낭비시키므로 좋지 않음
##### 인증 사슬 길이
* 신뢰 사슬을 확인하기 위해서는 브라우저가 웹사이트의 인증서를 시작으로 상위 인증서 사슬을 하나씩 거쳐 신뢰할 수 있는 최상위까지 도달
##### OCSP 스테이플링(stapling)
* 모든 신규 TLS 커넥션에서는 브라우저가 인증서 사슬의 서명을 확인
* 브라우저는 해당 인증서가 폐기되었는지도 확인
* 브라우저는 주기적으로 인증기관의 CRL을 다운로드하여 캐시헤 저장, '실시간' 체크를 위해서 인증 단계에서 OCSP 요청을 보내기도 함
* 서버가 인증서 사슬에 OCSP 응답을 포함시킴으로써 브라우저가 온라인 체크 과정을 생략 할 수 있음 (OCSP 스테이플링)
##### HTTP 엄격한 전송 보안 (HTTP Strict Transport Security, HSTS)
* 서버가 HTTP 헤더를 이용해서 브라우저에게 접속 규칙을 지정하는 보안 정책 메커니즘
##### 성능 체크리스트
* TCP에서 얻을 수 있는 최고의 성능을 얻어라
* TLS 라이브러리를 최신 릴리스 버전으로 업그레이드하고 그에 맞추어 서버를 구축하라
* 세션 캐싱과 상태를 유지하지 않는 재개를 활성화하고 그에 맞게 설정하라
* 세션 캐싱 히트율를 모니터링하고 그에 맞게 설정을 조정하라
* TLS 세션을 사용자와 가까운 곳에서 종료시켜 왕복 레이턴시를 최소화하라
* TLS 레코드 크기를 단일 TCP 조각에 맞도록 조정하라.
* 인증 사슬이 초기 혼잡 윈도 크기를 넘지 않도록 하라.
* 인증 사슬에서 불필요한 인증서를 제거하라. 사슬의 길이를 최소화하라.
* 서버의 TLS 압축 기능을 비활성화하라
* 서버 이름 표시 (SNI)를 설정하라
* 서버의 OCSP 스테이플링 기능을 설정하라
* HSTS 헤더를 첨부하라
#### 테스트 검증
* Qualys SSL Server Test 온라인 서버를 이용
## 2부 무선 네트워크 성능
### 5장 무선 네트워크 소개
#### 유비쿼터스 환경
* 광범위하게는 무선 네트워크란 케이블 선으로 연결되지 않은 모든 네트워크를 말함
* WiFi, Bluetooth, ZigBee, NFC, WiMAX, LTE, HSPA, EV-DO, 초기 3G 표준, 위성서비스 등
##### 무선 네트워크의 종류
종류 | 범위 | 사용차 | 표쥰 규격
:--- | :--- | :--- | :---
Personal Area Network (PAN) | 개인 | 기기 간 무선 연결 | Bluetooth, ZigBae, NFC
Local Area Network (LAN) | 빌딩이나 구역 내 | 유선 네트워크의 무선 확장 | IEEE 802.11 (WiFi) 
Metropolitan Area Network (MAN) | 도시네트워크 간 | 무선 연결 | IEE 802.15 (WiMAX) 
Personal Area Network (PAN) | 전세계 | 무선 네트워크 연결 | Cellular (UMTS, LTE 등)
#### 무선 네트워크 성능의 기초 원리
##### 대역폭
* <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bae6b1970ad71932f5f9e41fcb283a72f78b3d7c">
* 네트워크 구간을 단독으로 사용하는 케이블로 연결하는 유선 네트워크와 달리 전파통신은 본질적으로 전파, 혹은 전자파라는 매체를 공유하게 됨
* 전체적인 채널의 비트 전송 속도는 지정된 주파수 범위와 정비례
* 모든 주파수 범위가 똑같은 성능을 보장해 주지는 않음
* 낮은 주파수의 신호는 더 멀리 넓게 이동하지만 커다란 안테나를 필요로 하고 해당 주파수 대역의 접속을 원하는 많은 클라이언트가 존재하여 경쟁이 치열
##### 신호 강도
* 신호 대 잡음 비(SNR), 혹은 송신자와 수신자 간의 신호 강도는 대역폭과 함께 무선통신의 근간이 되는 제약조건
* 모든 전파 통신은 이동 매체를 공유하기 때문에 다른 기기들이 방해 전파를 생성할 수 밖에 없음
* Near-far problem : 강한 신호가 약한 신호를 '밀어내' 수신자가 상대적으로 약한 신호를 받지 못하는 현상
* Cell-breathing : 누적된 잡음이나 방해 신호의 강도에 따라 통신 가능 구역, 혹은 신호 범위가 늘거나 주는 현상
##### 변조
* 디지털 신호를 아날로그 신호로 변환하는 과정이 바로 변조
* 몇 비트의 알파벳을 이용하느냐에 따라 변조 효율이 달라짐
* 알파벳과 심벌 레이트를 조합하여 통신 채널의 최종적인 처리량을 알아낼 수 있음
#### 실제 무선 통신 성능 측정하기
* 최대로 잡음과 방해 신호를 줄이고 송신자와 수신자를 가능한 가까이 두고 그들에게 필요한 전력을 모두 공급해 줘야 하고 또한 가장 효율적인 변조 방식을 선택해야 할 것
### 6장 와이파이 (WiFi)
* 와이파이 얼라이언스라는 무역 협회의 등록 상표로, 이 협회는 무선랜 기술들과 장치 간의 연결 표준 기술, 테스트 수행을 목적으로 설립
#### 이더넷에서 무선 랜으로
* 와이파이는 혼잡 회피 매커니즘에 의존
* 각 송신자가 충돌을 방지하기 위해 오직 채널이 유후 상태임을 확인했을 때 메시지 전체를 한꺼번에 보내도록 하는 방식
* 와이파이 프레임이 전송되면 전송자는 다음 ㅔㄷ이터를 전송하기 전에 수신자로부터 데이터를 받았다는 확실한 신호를 받을 때까지 대기
#### 와이파이 표준과 기능 들
802.11 protocol | Release | Freq(GHz) | Bandwidth(MHz) | Data rate per stream (Mbit/s)
:--- | :--- | :--- | :--- | :---
b | Sep 1999 | 2.4 | 20 | 1,2,5.5,11
g | Jun 2003 | 2.4 | 20 | 6,9,12,18,24,36,48,54
n | Oct 2009 | 2.4 | 20| 7.2, 14.4, 21.7, 28.9, 43.3, 57.8, 65, 72.2
n | Oct 2009 | 5| 40| 15, 30, 45, 60, 90, 120, 135, 150
ac| - 2014 | 5| 20,40,80,160| up to 866.7
#### 와이파이 성능의 측정과 최적화
* 전형적인 와이파이 성능이라는 것은 존재하지 않음
* 와이파이의 작동 범위는 사용하는 표준 기술, 사용자의 위치, 사용하는 기기, 그 지억에서 사용하는 무선전파 환경에 따라 달라짐
##### 와이파이 네트워크에서 패킷 손실
* 와이파이를 통해 데이터를 전달할 때에 TCP 패킷 손실은 분명 문제가 될 수 있으나, TCP 패킷 손실의 절대적인 비율을 놓고 보면 유선 네트워크와 크게 다를 바가 없음
#### 와이파이 네트워크의 최적화
##### 미계량 대역폭을 활용하라
#### 가변 대역폭에 적응하라
* 네트워크를 사용하는 위치가 조금이라도 바뀌거나 주변 무선 기기의 행동이 바뀌거나, 그 밖의 전반적인 무선 환경의 변화에 따라서 사용할 수 있는 대역폭은 시시작각으로 바뀜
##### 가변 레이턴시에 적응하라
### 7장 모바일 네트워크
#### 세대별 무선 네트워크 역사
세대 | 최고 데이터율 | 설명
:--- | :--- | :---
1G | 데이터 없음 | 아날로그 시스템
2G | Kbit/s | 아날로그 시스템과 병렬로, 혹은 중첩으로 구축된 첫 디지털 시스템
3G | Mbit/s | 아날로그 시스템과 병렬로 구축된 전용 디지털 네트워크
4G | Gbit/s | 디지털과 패킷만으로 운용되는 네트워크
##### 2G에서 시작된 데이터 서비스
##### 3GPP와 3GPP2 파트너십 
#### 3G 기술의 진화
##### 3GPP3 기술의 진화
##### IMT-Advanced 4G 요구사항
##### 롱텀 에볼루션 (Long Term Evolution, LTE)
##### HSPA+의 세계 4G 시장 선도
##### 다세대 네트워크를 위한 대비
#### 디바이스의 특징과 기능
##### 사용자 장비 카테고리
#### 무선 전파 리소스 컨트롤러
* 3G와 4G 네트워크에는 유선이나 와이파치 네트워크에 없는 무선 전파 리소스 컨트롤러(RRC)라는 독특한 기능이 있음
* RRC는 사용하는 기기와 기지국 사이의 모든 커넥션을 관리하고 중재
* RRC는 레이턴시, 처리량, 배터리 수명 등 사용 기기의 성능에 직접적으로 연관
* 엑세스 포인트에서 전송 트래픽 지시 메시지(delivery traffic indication message, DTIM)를 정기적으로 전송하여 특정 클라이언트에게 데이터 전송 사실을 알림
* RRC는 누가 언제 데이터를 보내고, 대역폭을 어떻게 할당하며 신호 전력을 어떻게 쓸 것이고 각 기기의 전력 상태는 어떤지 같은 수많은 변수를 관리
##### 3G, 4G 그리고 와이파이의 전력 요건
* 신호가 강하면 높은 처리량을 얻을 수 있다. 하지만 대량의 데이터 전송에는 상당한 에너지를 소비하기 때문에 배터리 수명에는 악영향
* 신호 강도를 낮추면 송신탑과의 연결 자체가 끊어질 수 있음
##### LTE RRC 상태 기계
* 모든 LTE 기기의 무선 전파 상태는 사용자와 연결된 방송탑에서 관리
* 3GPP 표준에서 정의한 RRC 상태 기계가 네트워크에 연결된 기기에게 가능한 모든 전력 상태를 정의
##### HSPA와 HSPA+(UMTS) RRC 상태 기계
##### EV-DO(CDMA) RRC 상태 기계
##### 비효율적인 주기적 전송
#### 통시사 네트워크 종단 간 아키텍처 (End-to-End Carrier Architecture)
##### 무선 접속망
##### 코어 네트워크
##### 백홀 용량과 레이턴시
#### 모바일 네트워크 패킷 흐름
##### 요청 보내기
##### 인바운드 데이터 흐름
#### 이종 네트워크
#### 실환경에서의 3G, 4G 그리고 WiFi성능
### 8장 모바일 네트워크 최적화
* 애플리케이션이 사용하는 프로토콜은 같아도 물리적인 전송 계층에 존재하는 여러 제약사항을 제대로 대처하지 않으면 응답속도가 느려지거나 레이턴시의 변동이 심해짐
* 네트워크 성능을 충분히 이해하지 않고 개발한 애플리케이션은 당연히 배터리 성능에도 좋지 않은 영향을 끼침
#### 배터리 전력 손실 줄이기
* 무선 전파가 활성화 되어 있을 때 데이터 전송을 최대화 시키고, 그 밖에 추가적인 데이터 전송을 줄이는 것을 목표로 함
#### 주기적이고 비효율적인 데이터 전송 제거
* 폴링(polling)은 모바일 네트워크에서는 특히 전력 소모가 많으므로 최소화하라.
* 가능하면 폴링 대시 푸시(push) 전달과 알림 신호가 사용되어야 한다.
* 아웃바운드와 인바운드 요청 모두 통합 처리해아 한다.
* 중요도가 낮은 요청은 무선 전파가 활성화될 때까지 미루어야 한다.
#### 네트워크 인터페이스의 종류를 다양하게 설계하기
#### 데이터를 한 번에 집중적으로 전송하고 유후 상태로 돌아가기
#### 와이파이(WiFi) 네트워크로 떠넘겨라
#### 프로토콜 애플리케이션 지침을 적용하라
## 3부 HTTP
### 9장 HTTP의 간략한 역사
#### HTTP 0.9:간단한 한 줄짜리 프로토콜
* 팀 버너스 리가 발표한 HTTP 초기 제안서에서는 간략함이라는 철학을 가지고 HTTP가 설계됨
* HTTP 0.9의 기능 요약
  * 클라이언트와 서버 간의 요청-응답 프로토콜이다.
  * TCP/IP 연결 위에서 동작하는 ASCII 프로토콜이다.
  * 하이퍼텍스트 문서(HTML)을 전송하기 위해 만들어졌다.
  * 서버와 클라이언트 간의 커넥션은 매번 요청이 끝날 때마다 종료된다.
#### HTTP 1.0:급속 성장과 정보성 RFC
* 1996년 5월에 이르러서는 HTTP 워킹 그룹에서 수많은 HTTP 1.0 버전의 공통적인 사용 시나리오를 담은 RFC-1945 발표
* RFC는 오로지 정보 제공 차원에서 만들어진 것으로써, 우리가 현재 알고 있는 HTTP 1.0은 공식 규격도 아니고 인터넷 표준도 아님
* HTTP 1.0의 주된 변환
  * 요청은 헤더 필드로 구분된 몇 개의 라인으로 구성될 수 있다.
  * 응답 오브젝트는 응답 상태 값을 앞부분에 표기하여 구성하고 있다.
  * 응답 오브젝트는 헤더 필드로 구분된 라인으로 구성되어 있다.
  * 응답 오브젝트는 하이퍼텍스트로 한정되어 있지 않다.
  * 서버와 클라이언트 간의 커넥션을 매번 요청이 끝날 때마다 종료된다.
#### HTTP 1.1:인터넷 표준
* HTTP 1.0의 문서화 작업과 더불어 HTTP를 공식적인 인터넷 국제 표준화 기구를 통해서 표준화하는 작업이 1995년에서 1999년에 걸쳐 동시에 진행
* HTTP 1.1 표준은 초기 버전 프로토콜의 애매모호한 부분들을 대폭 수정
* 킵얼라이브 커넥션, 블록 단위 인코딩 전송, 바이트 범위의 요청, 추가 캐시 메커니즘, 전송 인코딩, 요청 파이프라이닝 등의 기능을 추가하여 성능 최적화
#### HTTP 2.0: 전송 성능을 개선하다
* 2012년 초, HTTPbis 워킹 그룹이 HTTP 2.0에 대한 계획을 발표
* HTTP 2.0의 주된 목적은 전송 성능을 개선하고 낮은 레이턴시와 높은 처리량을 얻는 것
* HTTP 헤더, 수치, 사용 사례와 같은 상위 수준의 프로토콜 시맨틱은 전혀 번하지 않음
### 10장 웹 성능 이해의 첫걸음
#### 하이퍼텍스트, 웹 페이지 그리고 웹 애플리케이션
* 하이퍼텍스트 문서 : 하이퍼텍스트 문서는 월드 와이드 웹의 기원이며, 기본적인 서식과 하이퍼링크를 내재한 텍스트 문서
* 웹 페이지 : HTML 워킹그룹과 초기 브라우저 제작업체들이 하이퍼텍스트의 정의를 확장시켜 이미지나 오디오와 같은 하이퍼미디어 리소스를 제공할 수 있도록 했고 더 풍부한 레이아웃을 제공할 수 있는 토대를 마련
* 웹 애플리케이션 : 자바스크립트의 출현과 Dynamic HTML(DHTML)과 AJAX의 발전이 다시 한번 판도를 바꾸었고, 단순한 웹 페이지를 상호작용이 가능한 웹 애플리케이션으로 탈바꿈시킴
#### 현대 웹 애플리케이션의 구조
##### 속도, 성능 그리고 인간의 인지도
지연시간 | 사용자의 인식
:--- | :---
0 - 100ms | 즉각적
100 - 300ms | 인식할 만한 아주 작은 지연이 존재
300 - 1000ms | 기기가 정상적으로 동작하고 있다고 느낌
1,000+ms | 딴 생각을 하기 시작함
10,000+ms | 작업을 포기함
##### 리소스 워터폴 분석하기
* 리소스 워터폴은 사용 가능한 네트워크의 성능 진단 도구 중 가장 통찰력 있는 도구
#### 성능의 큰 기둥:컴퓨팅, 렌터링, 네트워킹
##### 대역폭을 늘려도 큰 영향은 없다
* 수십 개의 호스트로부터 수백 개의 작은 리소스를 얻어야 하는 일상적인 웹 브라우징에 있어서는 왕복 레이턴시가 더 큰 제한요소
##### 레이턴시가 성능에 병목이 된다.
* 대역폭을 업그레이드한다고 해서 웹 브라우징 속도가 그다지 빨라지지 않을 것이라는 결론
* 대용량 미디어 파일을 스트리밍하거나 업로드하는 속도는 빨라질지 몰라도 그 파일들을 담고 있는 페이지를 로딩하는 속도는 그다지 빨라지지 않음
##### 가상 사용자와 실제 사용자 성능 측정
* 웹 애플리케이션 성능을 측정하는 작업은 간단하지 않음
* 모든 애플리케이션에게 맞는 지표가 존재하지 않음
* 기준이 완성되면, 가상 사용자와 실제 사용자의 성능 측정을 결합한 성능 데이터를 수집
#### 브라우저 최적화
* 문서 인식 최적화 : 네트워킹 스택이 문서, CSS, 자바스크립트 파싱 파이프라인과 연계되어 있어서 중요한 네트워크 자산이 무엇인지 알아낸 후 우선순위를 정하여 그들을 먼저 전송한다. 그 후 가능한 한 빨리 페이지를 상호작용이 가능한
상태로 만든다. 이는 종종 리소스 우선순위 할당을 통해서나 룩어헤드 파싱, 혹은 이와 비슷한 기법을 통하여 수행된다.
* 추론 최적화 : 브라우저가 장시간 동안 사용자의 행동 패턴을 알아내어 추론 최적화를 수행 할 수 있다. 브라우저는 DNS 이름을 미리 알아내고 가능성 있는 호스트명에 미리 연결하는 등 사용자가 앞으로 행동을 예측할 수 있다.
* 리소스 프리페칭 및 우선순위 : 문서, CSS, 자바스크립트 파서가 네트워크 스택과 추가적인 정보를 나눔으로써 각 리소스의 상대적인 우선순위를 정할 수 있다. 첫 렌더링에 필요한 블로킹 리소스는 높은 순위를 부여받고, 낮은 순위의 요청은
임시적으로 대기열의 뒤로 이동하게 된다.
* DNS 사전 해결 : 연결 가능성이 높은 호스트명을 미리 알아내어 앞으로 있을 HTTP 요청에 DNS 레이턴시를 줄인다. 사전 해결은 사용자가 페이지의 링크 위에 마우스를 올리는 것 같은 네비게이션 기록을 통하여 학습한 것을 토대로 수행 할 
수 있다.
* TCP 사전 연결 : DNS 조회를 수행한 후에 브라우저는 HTTP 요청에 대비하여 TCP 커넥션을 예측하여 생성할 수 있다. 만약 예측이 맞았다면 TCP 핸드셰이크에 필요한 왕복 네트워크 레이턴시를 완전히 제거할 수 있게 된다.
* 페이지 사전 렌더링 : 일부 브라우저는 사용자가 앞으로 향할 목적지를 예측하여 그 페이지 전체를 숨겨진 탭에서 미리 렌더링해 놓을 수 있다. 그런 다음 사용자가 실제로 네비게이션을 시작할 때에 즉시 탭을 전환하게 된다.
### 11장 HTTP 1.x
* HTTP의 성능을 개선하는 것이 HTTP 1.1 워킹 그룹의 가장 핵싱적인 설계 목표
* 1.1 표준은 실제로 성능과 기능면에서 많은 개선을 이루어냄
* 성능과 기능 개선
  * 지속적으로 연결되어 있는 커넥션을 통해 재사용을 가능하게 함.
  * 청크된 전송 인코딩을 이용하여 응답 스트리밍을 가능하게 함.
  * 바이트 서빙 기법을 통하여 범위를 지정한 리소스 요청을 가능하게 함
  * 캐싱 메커니즘을 명확히 정의하고 성능을 향상시킴.
* DNS 룩업을 줄여라
  * 호스트명을 알아내는 데는 한 번의 네트워크 왕복이 필요
  * 룩업이 진행 중일 때는 요청을 받지 않으므로 요청 발생 시 레이턴시를 유발
* HTTP 요청을 최소화하라
  * 요청을 보내지 않아도 된다면 보내지 않는 것이 가장 좋은 최적화 방법
  * 페이지 내의 불필요한 리소스를 제거
* 콘텐츠 전송 네트워크를 이용하라 
  * 클라이언트와 지역적으로 가까운 곳에 데이터를 위치시키면 TCP 커넥션의 네트워크 레이턴시를 대폭 줄일 수 있고 처리량도 개선
* Expires 헤더를 추가하고 ETag를 설정하라
  * 중요한 리소스를 캐시에 저장하여 페이지의 모든 데이터마다 매번 요청을 보내지 않음
  * Expires 헤더는 오브젝트의 캐시 수명을 설정할 있음 
  * 사용자의 캐시에서 오브젝트를 직접 가져와 HTTP 요청 자체를 없앨 수 있음 
  * ETag와 Last-Modified 헤더는 마지막 업데이트된 시간을 기억함으로써 효율적인 캐시 재인증 매커니즘을 제공
* 데이터를 Gzip 압축하라
  * 텍스트 기반의 모든 데이터는 전송될 때에 Gzip으로 압축
  * Gzip은 서버에서 플래그를 설정하는 것만으로도 파일의 크기를 평균 60-80%까지 줄일 수 있음
  * 간단하면서도 큰 효과를 볼 수 있는 최적화 방법
* HTTP 리다이렉션을 피하라
  * HTTP 리다이렉션은 비용 소모가 큰 작업
  * 특히 클라이언트를 다른 호스트명으로 이동시켜야 할 때에는 DNS 룩업, TCP 커넥션 레이턴시 등의 추가적인 비용이 발생
#### 킵 얼라이브 커넥션의 장점
* 킵얼라이브 없이는 모든 요청이 두 번의 왕복 레이턴시를 유발
* 킵얼아이브 이용하면 첫 요청에서는 두 번의 왕복시간이 소요되지만, 그다음 요청부터는 단 한 번의 왕복 레이턴시가 소요
#### HTTP 파이프라이닝
* FIFO 큐를 클라이언트 쪽에서 서버 쪽으로 재배치하는 것
* 첫 요청이 끝나기를 기다리자 않고 바로 두 번째 요청을 처리하기 시작
* 서버상에 병렬적으로 처리는 미묘한 문제를 일으키며 HTTP 1.x 프로토콜에서는 중요한 한계점을 드러냄
* HTTP 1.x은 같은 커넥션에서 여러 응답을 섞어 보내지 않고, 응답의 모든 바이트가 완전히 전송되기 전에는 다음 응답을 전송할 수 없음
* HTTP 파이프라인을 도입하는 작업은 많은 이점이 있음에도 불구하고 여전히 매우 한정적으로 이루어짐
#### 다수의 TCP 커넥션을 사용하기
* 호스트당 여섯 개의 독립적인 커넥션
  * 장점
    * 클라이언트는 병렬로 최대 여섯 개의 요청을 보낼 수 있음
    * 서버는 병렬로 최대 여섯 개의 요청을 처리 할 수 있음
    * 첫 왕복에 전송 가능한 누적 패킷 수는 여섯 배로 늘어남
  * 단점
    * 소켓 수가 늘어나면서 클라이언트, 서버, 그리고 모든 중계자가 추가 메모리 버퍼와 CPU 오버헤드 등 리소스를 소모
    * 병렬 TCP 스트림 간에 대역폭 경쟁이 일어남
    * 여러 소켓을 동시에 처리하는 작업을 구현하는데 까다로움
    * 병렬의 TCP 스트림을 활용해도 애플리케이션에서는 병렬 작업이 제한적으로 이루어짐
  * 채택 이유
    * 애플리케이션 프로토콜(HTTP)이 갖는 제약의 해법
    * TCP의 혼잡 윈도 크기의 낮은 시작값 문제의 해법
    * TCP 윈도 스케일링을 사용할 수 없는 클라이언트를 위한 해법
#### 도메인 샤딩
* 모든 리소스를 하나의 호스트에서 제공하는 대신 수동으로 그들을 하나의 호스트에서 제공하는 대신 수동으로 그들을 하위 도메인으로 쪼갤 수 있음
* 호스트명마다 추가적으로 DNS 룩업이 필요하고 소켓이 추가될 때마다 클라이언트와 서버 양쪽의 리소스를 소모
* 리소스가 어디로 어떻게 쪼개지는가를 사이트 관리자가 직접 관리
* 주의사항
  * TCP를 최대한 활용
  * 브라우저는 자동으로 여섯 개의 커넥션을 생성
  * 리소스의 수, 크기, 응답 시간에 따라 최적의 샤딩 수가 달라짐
  * 클라이언트 레이턴시와 대역폭에 따라 최적의 샤딩 수가 달라짐
  * 도메인 샤딩은 추가적인 DNS 룩업과 TCP 느린 시작으로 인하여 성능에 영향을 줄 수 있음
#### 프로토콜 오버헤드를 측정하고 조절하기
